# Core Concepts

## Log Types

OpenShift logging at a high level aggregates three types of logs:

1.  application - Container logs generated by user applications running in the cluster, except infrastructure container applications.

2.  infrastructure - Logs generated by infrastructure components running in the cluster and OpenShift Container Platform nodes, such as journal logs. Infrastructure components are pods that run in the `openshift*`, `kube*`, or `default` projects.

3.  audit - Logs generated by the node audit system (auditd), which are stored in the `/var/log/audit/audit.log` file, and the audit logs from the Kubernetes apiserver and the OpenShift apiserver.  By default, these logs are not stored in the internal Elasticsearch due to this Elasticsearch log store not being secure.  [You can however turn this on](https://docs.openshift.com/container-platform/4.7/logging/config/cluster-logging-log-store.html#cluster-logging-elasticsearch-audit_cluster-logging-store).

## Major Logging Components

OpenShift at a high level has 3 major components:

1.  collection - This is the component that collects logs from the cluster, formats them, and forwards them to the log store. The current implementation is Fluentd.

2.  log store - This is where the logs are stored. The default implementation is Elasticsearch. You can use the default Elasticsearch log store or forward logs to external log stores. The default log store is optimized and tested for short-term storage.

3.  visualization - This is the UI component you can use to view logs, graphs, charts, and so forth. The current implementation is Kibana.

### Collection

The Fluentd collector collects logs from these sources:

1.  journald for all system and infra logs.  These logs are generated by the OS, container runtime and OCP

2.  `/var/log/containers/*.log` for all container logs.  These logs are generated by CRI-O container engine

3.  `/var/log/audit/audit.log` for all audit logs

The logs collected are best effort; not every log entry is gaurenteed to be delivered, nor are each entry gaurenteed to be unique.  [Information on how to configure the collector can be found here](https://docs.openshift.com/container-platform/4.7/logging/config/cluster-logging-collector.html#cluster-logging-collector).

### Log Store

The OpenShift Logging Elasticsearch instance is optimized and tested for short term storage, ~7 days.  If longer is required, it is recommended to use a third-party system.  Elasticsearch organizes logs from Fluentd into datastores called `indices`.  Each indice is subdivided into `shards`.  The number of Elasticsearch shards == the number of Elasticsearch data nodes.  You can additionally configure Elasticsearch to make copies of these shards, called `replicas`, which Elasticsearch spreads across the Elasticsearch nodes.  The number of shards (number of Elasticsearch nodes), replicas, and log retention can be configured by using the `ClusterLogging` custom resource.  [More information on how to configure it can be found here](https://docs.openshift.com/container-platform/4.7/logging/config/cluster-logging-log-store.html#cluster-logging-store).

### Visualization

Kibana is the visualization tool.  [Information to configure it can be found here](https://docs.openshift.com/container-platform/4.7/logging/config/cluster-logging-visualizer.html#cluster-logging-visualizer).


### Event Router

While not a major component, this Event Router is a pod that watches OCP events, collects and writes them out to `STDOUT` for Fluentd to collect and forward.  Elasticsearch indexes these events to the `infra` index.  [You must manually configure it](https://docs.openshift.com/container-platform/4.7/logging/cluster-logging-eventrouter.html#cluster-logging-eventrouter).

### Log Forwarding

This is also not a major component, but can be incredibly useful if your organization already has a centralized logging solution.  You can forward logs from OCP to this by [following these instructions](https://docs.openshift.com/container-platform/4.7/logging/cluster-logging-external.html#cluster-logging-external).
